{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYYC56pWHdZP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import (accuracy_score, f1_score, roc_auc_score,\n",
        "                             mean_squared_error, r2_score, confusion_matrix)\n",
        "\n",
        "# ===================== SETTINGS =====================\n",
        "REMOVE_OUTLIERS = True  # Remove outliers for regression\n",
        "VISUALIZE = True        # Generate plots\n",
        "\n",
        "# ===================== LOAD TRAIN DATA =====================\n",
        "df = pd.read_csv('/kaggle/input/ai-201-b-mse-2-aiml-c/train.csv')\n",
        "target_col = df.columns[-1]\n",
        "df = df.dropna(subset=[target_col])\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]\n",
        "\n",
        "# ===================== FEATURE TYPES =====================\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "print(\"Feature types summary:\")\n",
        "print(f\"Numeric ({len(numeric_cols)}): {numeric_cols}\")\n",
        "print(f\"Categorical ({len(categorical_cols)}): {categorical_cols}\")\n",
        "\n",
        "# ===================== TARGET VISUALIZATION =====================\n",
        "if VISUALIZE:\n",
        "    plt.figure(figsize=(6,4))\n",
        "    if y.dtype.kind in 'O' or y.dtype.name == 'category':  # categorical\n",
        "        sns.countplot(x=y)\n",
        "        plt.title(f\"Target Distribution: {target_col}\")\n",
        "    else:\n",
        "        sns.histplot(y, kde=True)\n",
        "        plt.title(f\"Target Distribution: {target_col}\")\n",
        "    plt.show()\n",
        "\n",
        "# ===================== BOX PLOT =====================\n",
        "if VISUALIZE and numeric_cols:\n",
        "    plt.figure(figsize=(12,6))\n",
        "    X[numeric_cols].boxplot(rot=45)\n",
        "    plt.title(\"Boxplots of Numeric Features\")\n",
        "    plt.show()\n",
        "\n",
        "# ===================== CORRELATION HEATMAP =====================\n",
        "if VISUALIZE and numeric_cols:\n",
        "    plt.figure(figsize=(10,8))\n",
        "    corr = X[numeric_cols].corr()\n",
        "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
        "    plt.title(\"Correlation Heatmap of Numeric Features\")\n",
        "    plt.show()\n",
        "\n",
        "# ===================== CATEGORICAL COUNTS =====================\n",
        "if VISUALIZE and categorical_cols:\n",
        "    for col in categorical_cols:\n",
        "        plt.figure(figsize=(6,4))\n",
        "        sns.countplot(x=col, data=X, order=X[col].value_counts().index)\n",
        "        plt.title(f\"Counts of {col}\")\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.show()\n",
        "\n",
        "# ===================== TASK DETECTION =====================\n",
        "def detect_task(y):\n",
        "    if y.dtype.kind in 'biufc' and y.nunique() > 10:\n",
        "        return 'regression'\n",
        "    else:\n",
        "        return 'classification'\n",
        "\n",
        "task_type = detect_task(y)\n",
        "print(f\"Detected task type: {task_type}\")\n",
        "\n",
        "# ===================== TRAIN-TEST SPLIT =====================\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ===================== OUTLIER REMOVAL =====================\n",
        "def remove_outliers_iqr(df, numeric_cols):\n",
        "    df_clean = df.copy()\n",
        "    for col in numeric_cols:\n",
        "        Q1 = df_clean[col].quantile(0.25)\n",
        "        Q3 = df_clean[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower = Q1 - 1.5 * IQR\n",
        "        upper = Q3 + 1.5 * IQR\n",
        "        df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]\n",
        "    return df_clean\n",
        "\n",
        "if REMOVE_OUTLIERS and task_type == 'regression':\n",
        "    train_combined = X_train.copy()\n",
        "    train_combined[target_col] = y_train\n",
        "    train_clean = remove_outliers_iqr(train_combined, numeric_cols)\n",
        "    X_train = train_clean.drop(columns=[target_col])\n",
        "    y_train = train_clean[target_col]\n",
        "    print(f\"Training rows before: {train_combined.shape[0]}, after: {train_clean.shape[0]}\")\n",
        "\n",
        "# ===================== TARGET ENCODING =====================\n",
        "if task_type == 'classification':\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(y_train)\n",
        "    y_test = le.transform(y_test)\n",
        "\n",
        "# ===================== PREPROCESSOR =====================\n",
        "def get_preprocessor(numeric_cols, categorical_cols):\n",
        "    return ColumnTransformer(transformers=[\n",
        "        (\"num\", SimpleImputer(strategy='mean'), numeric_cols),\n",
        "        (\"cat_low\", Pipeline([\n",
        "            (\"imputer\", SimpleImputer(strategy='most_frequent')),\n",
        "            (\"onehot\", OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "        ]), [col for col in categorical_cols if df[col].nunique() <= 20]),\n",
        "        (\"cat_high\", Pipeline([\n",
        "            (\"imputer\", SimpleImputer(strategy='most_frequent')),\n",
        "            (\"ordinal\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
        "        ]), [col for col in categorical_cols if df[col].nunique() > 20])\n",
        "    ])\n",
        "\n",
        "preprocessor = get_preprocessor(numeric_cols, categorical_cols)\n",
        "\n",
        "# ===================== MODEL =====================\n",
        "model = RandomForestClassifier(n_estimators=200, max_depth=30, random_state=42) \\\n",
        "        if task_type=='classification' else \\\n",
        "        RandomForestRegressor(n_estimators=200, max_depth=30, random_state=42)\n",
        "\n",
        "# ===================== PIPELINE =====================\n",
        "pipeline = Pipeline([('preprocessor', preprocessor), ('model', model)])\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# ===================== EVALUATION =====================\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "if task_type == 'classification':\n",
        "    y_proba = pipeline.predict_proba(X_test)\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "    if y_proba.shape[1] > 2:\n",
        "        print(f\"ROC-AUC (OVR): {roc_auc_score(y_test, y_proba, multi_class='ovr'):.4f}\")\n",
        "    else:\n",
        "        print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba[:,1]):.4f}\")\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=le.classes_,\n",
        "                yticklabels=le.classes_)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()\n",
        "else:\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "    print(f\"R2 Score: {r2:.4f}\")\n",
        "\n",
        "\n",
        "# ===================== LOAD TEST DATA =====================\n",
        "df_test = pd.read_csv('/kaggle/input/ai-201-b-mse-2-aiml-c/test.csv')\n",
        "test_ids = df_test[\"id\"]\n",
        "X_test_final = df_test.drop(columns=['id'])\n",
        "\n",
        "# Add missing columns\n",
        "for col in X_train.columns:\n",
        "    if col not in X_test_final.columns:\n",
        "        X_test_final[col] = np.nan\n",
        "X_test_final = X_test_final[X_train.columns]\n",
        "\n",
        "# Transform and predict\n",
        "X_test_transformed = pipeline.named_steps['preprocessor'].transform(X_test_final)\n",
        "\n",
        "if task_type == 'classification':\n",
        "    y_test_pred = pipeline.predict(X_test_final)\n",
        "    y_test_pred = le.inverse_transform(y_test_pred)  # convert back to original labels\n",
        "    submission = pd.DataFrame({\n",
        "        \"id\": test_ids,\n",
        "        \"Prediction\": y_test_pred\n",
        "    })\n",
        "else:\n",
        "    y_test_pred = pipeline.predict(X_test_transformed)\n",
        "    submission = pd.DataFrame({\n",
        "        \"id\": test_ids,\n",
        "        \"Prediction\": y_test_pred\n",
        "    })\n",
        "\n",
        "\n",
        "#submission.insert(0, 'id', test_ids)\n",
        "submission.to_csv(\"submission_universal.csv\", index=False, float_format=\"%.6f\")\n",
        "print(\"submission.csv createdÂ successfully!\")"
      ]
    }
  ]
}